{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras Basics.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "CCQY7jpBfMur"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arunmadhuk/Machine-Learning/blob/master/Keras_Basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1xIRPtY0E1w"
      },
      "source": [
        "# About Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViAXWoKlZ8s6"
      },
      "source": [
        "Keras is an Open Source Neural Network library written in Python that runs on top of Theano or Tensorflow. It is designed to be modular, fast and easy to use. It was developed by Fran√ßois Chollet, a Google engineer.\n",
        "\n",
        "Keras doesn't handle low-level computation. Instead, it uses another library to do it, called the \"**Backend**\". So Keras is high-level API wrapper for the low-level API, capable of running on top of TensorFlow, CNTK, or Theano.\n",
        "\n",
        "Keras High-Level API handles the way we make models, defining layers, or set up multiple input-output models. In this level, Keras also compiles our model with loss and optimizer functions, training process with fit function. Keras doesn't handle Low-Level API such as making the computational graph, making tensors or other variables because it has been handled by the \"backend\" engine."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lh-OuTiM8vDX"
      },
      "source": [
        "# What is a Backend?\n",
        "Backend is a term in Keras that performs all low-level computation such as tensor products, convolutions and many other things with the help of other libraries such as Tensorflow or Theano. So, the \"backend engine\" will perform the computation and development of the models. Tensorflow is the default \"backend engine\" but we can change it in the configuration.\n",
        "\n",
        "## Theano, Tensorflow, and CNTK Backend\n",
        "\n",
        "\n",
        "* **Theano** is an open source project that was developed by the MILA group at the University of Montreal, Quebec, Canada. It was the first widely used Framework. It is a Python library that helps in multi-dimensional arrays for mathematical operations using Numpy or Scipy. Theano can use GPUs for faster computation, it also can automatically build symbolic graphs for computing gradients. On its website, Theano claims that it can recognize numerically unstable expressions and compute them with more stable algorithms, this is very useful for our unstable expressions.\n",
        "* **Tensorflow** is the rising star in deep learning framework. Developed by Google's Brain team it is the most popular deep learning tool. With a lot of features, and researchers contribute to help develop this framework for deep learning purposes.\n",
        "* **The Microsoft Cognitive Toolkit** or **CNTK** is an open-source deep learning framework that was developed by Microsoft Team. It can run on multi GPUs or multi-machine for training deep learning model on a massive scale. In some cases, CNTK was reported faster than other frameworks such as Tensorflow or Theano."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o_QlL-l9QGK"
      },
      "source": [
        "## Advantages of Keras\n",
        "### Fast Deployment and Easy to understand\n",
        "\n",
        "Keras is very quick to make a network model. If you want to make a simple network model with a few lines, Keras can help you with that. Look at the example below:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_dim=50)) #input shape of 50\n",
        "model.add(Dense(28, activation='relu')) #input shape of 50\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "```\n",
        "Because of friendly the API, we can easily understand the process. Writing the code with a simple function and no need to set multiple parameters.\n",
        "\n",
        "\n",
        "### Large Community Support\n",
        "\n",
        "There are lots of AI communities that use Keras for their Deep Learning framework. Many of them publish their codes as well tutorial to the general public.\n",
        "\n",
        "### Have multiple Backends\n",
        "\n",
        "You can choose Tensorflow, CNTK, and Theano as your backend with Keras. You can choose a different backend for different projects depending on your needs. Each backend has its own unique advantage.\n",
        "\n",
        "### Cross-Platform and Easy Model Deployment\n",
        "\n",
        "With a variety of supported devices and platforms, you can deploy Keras on any device like\n",
        "\n",
        "iOS with CoreML\n",
        "Android with Tensorflow Android,\n",
        "Web browser with .js support\n",
        "Cloud engine\n",
        "Raspberry Pi\n",
        "Multi GPUs Support\n",
        "\n",
        "You can train Keras with on a single GPU or use multiple GPUs at once. Because Keras has a built-in support for data parallelism so it can process large volumes of data and speed up the time needed to train it.\n",
        "\n",
        "## Disadvantages of Keras\n",
        "### Cannot handle low-level API\n",
        "\n",
        "Keras only handles high-level API which runs on top other framework or backend engine such as Tensorflow, Theano, or CNTK. So it's not very useful if you want to make your own abstract layer for your research purposes because Keras already have pre-configured layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsK5aF2xZ-40"
      },
      "source": [
        "## Import tf.keras\n",
        "\n",
        "`tf.keras` is TensorFlow's implementation of the\n",
        "[Keras API specification](https://keras.io). This is a high-level\n",
        "API to build and train models that includes first-class support for\n",
        "TensorFlow-specific functionality, such as [eager execution](#eager_execution),\n",
        "`tf.data` pipelines, and [Estimators](./estimators.md).\n",
        "`tf.keras` makes TensorFlow easier to use without sacrificing flexibility and\n",
        "performance.\n",
        "\n",
        "To get started, import **`tf.keras`** as part of your TensorFlow program setup:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APJ9ZOnki0OG"
      },
      "source": [
        "!pip install -q pyyaml  # Required to save models in YAML format"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgPcBFru0E1z"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "print(tf.VERSION)\n",
        "print(tf.keras.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lj03RamP0E13"
      },
      "source": [
        "`tf.keras` can run any Keras-compatible code, but keep in mind:\n",
        "\n",
        "* The `tf.keras` version in the latest TensorFlow release might not be the same\n",
        "  as the latest `keras` version from PyPI. Check `tf.keras.__version__`.\n",
        "* When [saving a model's weights](#weights_only), `tf.keras` defaults to the\n",
        "  [checkpoint format](./checkpoints.md). Pass `save_format='h5'` to\n",
        "  use HDF5."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e1LPcXx0gR6"
      },
      "source": [
        "## Build a simple model\n",
        "\n",
        "### Sequential model\n",
        "\n",
        "In Keras, you assemble ***layers*** to build *models*. A model is (usually) a graph\n",
        "of layers. The most common type of model is a stack of layers: the\n",
        "**`tf.keras.Sequential`** model.\n",
        "\n",
        "To build a simple, fully-connected network (i.e. multi-layer perceptron):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WM-DUVQB0E14"
      },
      "source": [
        "model = tf.keras.Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wad-FLgoDIXD"
      },
      "source": [
        "### Convolutional Layer \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzuKJsaADzq9"
      },
      "source": [
        "# Convolutional layer with 48 filters of size 3x3 and use ReLU as an activation function.\n",
        "model.add(layers.Conv2D(48, (3, 3), activation='relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bUm-o63DIdB"
      },
      "source": [
        "### MaxPooling Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALzwgS3qD0E5"
      },
      "source": [
        "# To downsample the input representation, use MaxPool2d and specify the kernel size\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYx_tREKDEeN"
      },
      "source": [
        "### Dense Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Htj2QM9EDy6i"
      },
      "source": [
        "# Adds a densely-connected layer with 64 units to the model:\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "# Add another:\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "# Add a softmax layer with 10 output units:\n",
        "model.add(layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBKhAnNhDIfP"
      },
      "source": [
        "### Dropout Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJxOWsOID1JB"
      },
      "source": [
        "# Adding dropout layer with 50% probability\n",
        "model.add(layers.Dropout(0.5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NR6reyk0E2A"
      },
      "source": [
        "## Compile, Train and Evaluate\n",
        "\n",
        "After we define our model, let's start to train them. It is required to compile the network first with the loss function and optimizer function. This will allow the network to change weights and minimized the loss.\n",
        "\n",
        "### Set up training\n",
        "\n",
        "After the model is constructed, configure its learning process by calling the\n",
        "`compile` method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJ4AOn090E2A"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  # Adds a densely-connected layer with 64 units to the model:\n",
        "  layers.Dense(64, activation='relu', input_shape=(32,)),\n",
        "  # Add another:\n",
        "  layers.Dense(64, activation='relu'),\n",
        "  # Add a softmax layer with 10 output units:\n",
        "  layers.Dense(10, activation='softmax')])\n",
        "\n",
        "model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HG-RAa9F0E2D"
      },
      "source": [
        "**`tf.keras.Model.compile`** takes three important arguments:\n",
        "\n",
        "* **`optimizer`**: This object specifies the training procedure. Pass it optimizer\n",
        "  instances from the `tf.train` module, such as\n",
        "  **`tf.train.AdamOptimizer`**, **`tf.train.RMSPropOptimizer`**, or\n",
        "  **`tf.train.GradientDescentOptimizer`**.\n",
        "* **`loss`**: The function to minimize during optimization. Common choices include\n",
        "  **mean square error (`mse`), `categorical_crossentropy`**, and\n",
        "  **`binary_crossentropy`**. Loss functions are specified by name or by\n",
        "  passing a callable object from the **`tf.keras.losses`** module.\n",
        "* **`metrics`**: Used to monitor training. These are string names or callables from\n",
        "  the **`tf.keras.metrics`** module.\n",
        "\n",
        "The following shows a few examples of configuring a model for training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "St4Mgdar0E2E"
      },
      "source": [
        "# Configure a model for mean-squared error regression.\n",
        "model.compile(optimizer=tf.train.AdamOptimizer(0.01),\n",
        "              loss='mse',       # mean squared error\n",
        "              metrics=['mae'])  # mean absolute error\n",
        "\n",
        "# Configure a model for categorical classification.\n",
        "model.compile(optimizer=tf.train.RMSPropOptimizer(0.01),\n",
        "              loss=tf.keras.losses.categorical_crossentropy,\n",
        "              metrics=[tf.keras.metrics.categorical_accuracy])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjI5rbi80E2G"
      },
      "source": [
        "### Input NumPy data\n",
        "\n",
        "For small datasets, use in-memory [NumPy](https://www.numpy.org/)\n",
        "arrays to train and evaluate a model. The model is \"fit\" to the training data\n",
        "using the `fit` method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CvP6L-m0E2I"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def random_one_hot_labels(shape):\n",
        "  n, n_class = shape # number of instance, number of classes\n",
        "  classes = np.random.randint(0, n_class, n) \n",
        "  labels = np.zeros((n, n_class))\n",
        "  labels[np.arange(n), classes] = 1\n",
        "  return labels\n",
        "\n",
        "data = np.random.random((1000, 32))\n",
        "labels = random_one_hot_labels((1000, 10)) # create training label with 1000 instances and 10 classes\n",
        "\n",
        "print (labels[:5]) # check the first 5 instances labels\n",
        "\n",
        "model.fit(data, labels, epochs=10, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-pnVaFe0E2N"
      },
      "source": [
        "**`tf.keras.Model.fit`** takes three important arguments:\n",
        "\n",
        "* **`epochs`**: Training is structured into *epochs*. An epoch is one iteration over\n",
        "  the entire input data (this is done in smaller batches).\n",
        "* **`batch_size`**: When passed NumPy data, the model slices the data into smaller\n",
        "  batches and iterates over these batches during training. This integer\n",
        "  specifies the size of each batch. Be aware that the last batch may be smaller\n",
        "  if the total number of samples is not divisible by the batch size.\n",
        "* **`validation_data`**: When prototyping a model, you want to easily monitor its\n",
        "  performance on some validation data. Passing this argument‚Äîa tuple of inputs\n",
        "  and labels‚Äîallows the model to display the loss and metrics in inference mode\n",
        "  for the passed data, at the end of each epoch.\n",
        "\n",
        "Here's an example using **`validation_data`**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFcXzVQa0E2N"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "data = np.random.random((1000, 32))\n",
        "labels = random_one_hot_labels((1000, 10))\n",
        "\n",
        "val_data = np.random.random((100, 32))\n",
        "val_labels = random_one_hot_labels((100, 10))\n",
        "\n",
        "model.fit(data, labels, epochs=10, batch_size=32,\n",
        "          validation_data=(val_data, val_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgGdlXso0E2X"
      },
      "source": [
        "### Evaluate and predict\n",
        "\n",
        "The `tf.keras.Model.evaluate` and `tf.keras.Model.predict` methods can use NumPy\n",
        "data and a `tf.data.Dataset`.\n",
        "\n",
        "To *evaluate* the inference-mode loss and metrics for the data provided:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhDbOHEK0E2Y"
      },
      "source": [
        "data = np.random.random((1000, 32))\n",
        "labels = random_one_hot_labels((1000, 10))\n",
        "\n",
        "model.evaluate(data, labels, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXUTmDfb0E2b"
      },
      "source": [
        "And to *predict* the output of the last layer in inference for the data provided,\n",
        "as a NumPy array:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e3JsSoQ0E2c"
      },
      "source": [
        "result = model.predict(data, batch_size=32)\n",
        "print(result.shape)\n",
        "print(result[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "453x4Z-VQjGP"
      },
      "source": [
        "## Save the Entire Model\n",
        "\n",
        "The entire model can be saved to a file that contains the weight values, the model's configuration, and even the optimizer's configuration. This allows you to checkpoint a model and resume training later‚Äîfrom the exact same state‚Äîwithout access to the original code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWd09fvUQpuo"
      },
      "source": [
        "# Create a trivial model\n",
        "model = tf.keras.Sequential([\n",
        "  layers.Dense(10, activation='softmax', input_shape=(32,)),\n",
        "  layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(data, labels, batch_size=32, epochs=5)\n",
        "\n",
        "\n",
        "# Save entire model to a HDF5 file\n",
        "model.save('my_model.h5')\n",
        "\n",
        "# Recreate the exact same model, including weights and optimizer.\n",
        "model = tf.keras.models.load_model('my_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rlrLZ7RkKz_"
      },
      "source": [
        "## Further References\n",
        "\n",
        "* [Keras Tutorials](https://www.tensorflow.org/guide/keras)\n",
        "* [Keras for Beginners](https://www.guru99.com/keras-tutorial.html#1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCQY7jpBfMur"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "z6X9omPnfO_h"
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}